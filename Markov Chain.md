---
tags:
  - ðŸŒ±
date: 12--Aug--2024
alias: 
modified: 12--Aug--2024
---
# Markov Chain
System that hops form a state to another forming a chain. Similar to that in [[Markov Decision Process]].
## Properties
- [[Markovian transition model|Markov assumption]]
## Components
- States
- Initial probability distribution
- Transition probability distribution

---
Links:
